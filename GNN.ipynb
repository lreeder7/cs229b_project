{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4eY__GdogsY"
   },
   "source": [
    "# GCAE implementation and visualizations\n",
    "This implementation uses [GVP](https://github.com/drorlab/gvp-pytorch), developed by B Jing et al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPARezWzrsfQ"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQ9XWdKZTT2V",
    "outputId": "c53b1af3-af88-4567-8066-f517daaa614f"
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib torch torch_geometric mdtraj tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiGBohXNUJi-",
    "outputId": "e6049023-a58c-4852-c04a-7644dcc9b0a4"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/drorlab/gvp-pytorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZVLK2DBUvwY"
   },
   "source": [
    "# IMPORTANT: in order to run ```!pip install gvp-pytorch/```  go into gvp-ptorch/setup.py and change \"sklearn\" to \"scikit-learn\" (on line 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtAkBktV41S6"
   },
   "source": [
    "# Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "9qc8UgJsUvIr",
    "outputId": "0c64f8e0-b8ba-4631-af9d-13da195b5270"
   },
   "outputs": [],
   "source": [
    "!pip install gvp-pytorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_sLb-STlTTzo"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math, random, time\n",
    "import torch, torch_geometric\n",
    "import torch.utils.data as data\n",
    "import torch.nn as nn\n",
    "import gvp.data\n",
    "from gvp import GVP, GVPConvLayer, LayerNorm\n",
    "\n",
    "import mdtraj as md\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GDVme0yw4xuJ"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FZEJ23weTTxF"
   },
   "outputs": [],
   "source": [
    "def create_structures(files, pdb):\n",
    "    topology = md.load(pdb).topology\n",
    "    start = time.time()\n",
    "    structures = {}\n",
    "    for file in files:\n",
    "        traj = md.load_xtc(file, top=pdb)\n",
    "        traj.center_coordinates()\n",
    "\n",
    "        # grab atoms we want\n",
    "        N_atoms = traj.atom_slice(topology.select(\"protein and name N and resn!= ACE and resn!= NME\"))\n",
    "        CA_atoms = traj.atom_slice(topology.select(\"protein and name CA and resn!= ACE and resn!= NME\"))\n",
    "        C_atoms = traj.atom_slice(topology.select(\"protein and name C and resn!= ACE and resn!= NME\"))\n",
    "        O_atoms = traj.atom_slice(topology.select(\"protein and name O and resn!= ACE and resn!= NME\"))\n",
    "\n",
    "        N_coords = N_atoms.xyz\n",
    "        CA_coords = CA_atoms.xyz\n",
    "        C_coords = C_atoms.xyz\n",
    "        O_coords = O_atoms.xyz\n",
    "\n",
    "        #backbone = traj.atom_slice(topology.select(\"protein and backbone\"))\n",
    "        #coords = backbone.xyz # has size (n_frames x n_atoms x 3)\n",
    "\n",
    "        #traj_coords = coords.reshape(-1, backbone.n_atoms*3).T # has size (n_atoms*3 x n_frames)\n",
    "        #print(traj_coords.shape)\n",
    "\n",
    "\n",
    "\n",
    "        for i in range(len(traj)):\n",
    "            coords = np.stack([N_coords[i,:,:], CA_coords[i,:,:], C_coords[i,:,:], O_coords[i,:,:]],1)\n",
    "            #print(coords.shape)\n",
    "            #coords = traj_coords[:,i]\n",
    "            #coords = np.expand_dims(coords, axis=1)\n",
    "            #structures.append({'coords':coords,\n",
    "            #                   'name': f'{file[5:-4]}_frame{i}',\n",
    "            #                   'seq': ['Q']*traj_coords.shape[0]})\n",
    "            structures[f'{file[5:-4]}_frame{i}'] = {'coords': coords,\n",
    "                                                    'name': f'{file[5:-4]}_frame{i}',\n",
    "                                                    'seq': ['Q']*coords.shape[0]} # seq doesn't matter for now\n",
    "    end = time.time()\n",
    "    print(\"create structures took\", round((end-start)/60,4), \"minutes\")\n",
    "    return structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H2uDoeGbTTuh"
   },
   "outputs": [],
   "source": [
    "class LigandDataset(gvp.data.ProteinGraphDataset):\n",
    "    def __init_(self, data_list,\n",
    "                num_positional_embeddings=16,\n",
    "                top_k=30, num_rbf=16, device=\"cpu\"):\n",
    "        for structure in data_list:\n",
    "            structure['seq'] = ['Q'] * structure['coords'].shape[0]\n",
    "        super(LigandDataset, self).__init__(data_list,\n",
    "                                            num_positional_embeddings,\n",
    "                                            top_k, num_rbf, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJk4QmjaTeAn"
   },
   "outputs": [],
   "source": [
    "class GCAE(nn.Module):\n",
    "    '''\n",
    "    Graph Convolutional AutoEncoder\n",
    "\n",
    "    Takes in protein structure graphs of type `torch_geometric.data.Data`\n",
    "    or `torch_geometric.data.Batch` and returns a 3D position per node of\n",
    "    shape [n_nodes, 3].\n",
    "\n",
    "    Should be used with `gvp.data.ProteinGraphDataset`, or with generators\n",
    "    of `torch_geometric.data.Batch` objects with the same attributes.\n",
    "\n",
    "    :param node_in_dim: node dimensions in input graph, should be\n",
    "                        (6, 3) if using features from GVP-GNN\n",
    "    :param node_h_dim: hidden node dimensions to use in intermediate layers\n",
    "    :param node_in_dim: edge dimensions in input graph, should be\n",
    "                        (32, 1) if using original features from GVP-GNN\n",
    "    :param edge_h_dim: hidden edge dimensions to embed to before use\n",
    "                       in intermediate layers\n",
    "    :param num_layers: number of layers in each of the encoder\n",
    "                       and decoder modules\n",
    "    :param drop_rate: rate to use in all dropout layers\n",
    "    '''\n",
    "    def __init__(self, node_in_dim, node_h_dim,\n",
    "                 edge_in_dim, edge_h_dim,\n",
    "                 num_layers=3, drop_rate=0.1, node_num=66):\n",
    "\n",
    "        super(GCAE, self).__init__()\n",
    "\n",
    "        self.node_num = node_num\n",
    "\n",
    "        self.W_v = nn.Sequential(\n",
    "            GVP(node_in_dim, node_h_dim, activations=(None, None)),\n",
    "            LayerNorm(node_h_dim)\n",
    "        )\n",
    "        self.W_e = nn.Sequential(\n",
    "            GVP(edge_in_dim, edge_h_dim, activations=(None, None)),\n",
    "            LayerNorm(edge_h_dim)\n",
    "        )\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "                GVPConvLayer(node_h_dim, edge_h_dim, drop_rate=drop_rate)\n",
    "            for _ in range(num_layers))\n",
    "\n",
    "\n",
    "        self.squeeze_layer = nn.Sequential(\n",
    "            nn.Linear(self.node_num*(node_h_dim[0]+node_h_dim[1]*3),1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=drop_rate),\n",
    "            nn.Linear(1024, 16)\n",
    "        )\n",
    "\n",
    "        self.unsqueeze_layer = nn.Sequential(\n",
    "            nn.Linear(16, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=drop_rate),\n",
    "            nn.Linear(1024, self.node_num*(node_h_dim[0]+node_h_dim[1]*3))\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "                GVPConvLayer(node_h_dim, edge_h_dim, drop_rate=drop_rate)\n",
    "            for _ in range(num_layers))\n",
    "\n",
    "        self.W_out = GVP(node_h_dim, (3, 0), activations=(None, None))\n",
    "\n",
    "\n",
    "    def forward(self, h_V, edge_index, h_E):\n",
    "        '''\n",
    "        Forward pass to be used at train-time or test-time.\n",
    "\n",
    "        :param h_V: tuple (s, V) of node embeddings\n",
    "        :param edge_index: `torch.Tensor` of shape [2, num_edges]\n",
    "        :param h_E: tuple (s, V) of edge embeddings\n",
    "        :param seq: int `torch.Tensor` of shape [num_nodes]\n",
    "        '''\n",
    "\n",
    "        h_V = (h_V[0].reshape(h_V[0].shape[0]*h_V[0].shape[1],h_V[0].shape[2]),\n",
    "               h_V[1].reshape(h_V[1].shape[0]*h_V[1].shape[1],h_V[1].shape[2],h_V[1].shape[3]))\n",
    "\n",
    "        h_E = (h_E[0].reshape(h_E[0].shape[0]*h_E[0].shape[1],h_E[0].shape[2]),\n",
    "               h_E[1].reshape(h_E[1].shape[0]*h_E[1].shape[1],h_E[1].shape[2],h_E[1].shape[3]))\n",
    "\n",
    "        h_V = self.W_v(h_V)\n",
    "        h_E = self.W_e(h_E)\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            h_V = layer(h_V, edge_index, h_E)\n",
    "\n",
    "        encoder_embeddings = h_V\n",
    "\n",
    "        flat_s = h_V[0].reshape(h_V[0].shape[0]//self.node_num, -1)\n",
    "        flat_V = h_V[1].reshape(h_V[1].shape[0]//self.node_num, -1)\n",
    "        h_V_stack = torch.cat((flat_s, flat_V),dim=1)\n",
    "        h_V_stack = self.squeeze_layer(h_V_stack)\n",
    "\n",
    "        h_V_small = torch.clone(h_V_stack)\n",
    "\n",
    "        h_V_stack = self.unsqueeze_layer(h_V_stack)\n",
    "\n",
    "        flat_s = h_V_stack[:,:self.node_num*encoder_embeddings[0].shape[1]]\n",
    "        flat_V = h_V_stack[:,self.node_num*encoder_embeddings[0].shape[1]:]\n",
    "        h_V = (flat_s.reshape(encoder_embeddings[0].shape),\n",
    "               flat_V.reshape(encoder_embeddings[1].shape))\n",
    "\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            h_V = layer(h_V, edge_index, h_E)\n",
    "        logits = self.W_out(h_V)\n",
    "\n",
    "        logits = logits.reshape(-1, self.node_num, 3)\n",
    "        return logits, h_V_small\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mq8AbTS9Lw38"
   },
   "outputs": [],
   "source": [
    "class GCAE2(nn.Module):\n",
    "    '''\n",
    "    Graph Convolutional AutoEncoder\n",
    "\n",
    "    Takes in protein structure graphs of type `torch_geometric.data.Data`\n",
    "    or `torch_geometric.data.Batch` and returns a 3D position per node of\n",
    "    shape [n_nodes, 3].\n",
    "\n",
    "    Should be used with `gvp.data.ProteinGraphDataset`, or with generators\n",
    "    of `torch_geometric.data.Batch` objects with the same attributes.\n",
    "\n",
    "    :param node_in_dim: node dimensions in input graph, should be\n",
    "                        (6, 3) if using features from GVP-GNN\n",
    "    :param node_h_dim: hidden node dimensions to use in intermediate layers\n",
    "    :param node_in_dim: edge dimensions in input graph, should be\n",
    "                        (32, 1) if using original features from GVP-GNN\n",
    "    :param edge_h_dim: hidden edge dimensions to embed to before use\n",
    "                       in intermediate layers\n",
    "    :param num_layers: number of layers in each of the encoder\n",
    "                       and decoder modules\n",
    "    :param drop_rate: rate to use in all dropout layers\n",
    "    '''\n",
    "    def __init__(self, node_in_dim, node_h_dim,\n",
    "                 edge_in_dim, edge_h_dim,\n",
    "                 num_layers=3, drop_rate=0.1, node_num=66):\n",
    "\n",
    "        super(GCAE2, self).__init__()\n",
    "\n",
    "        self.node_num = node_num\n",
    "\n",
    "        self.W_v = nn.Sequential(\n",
    "            GVP(node_in_dim, node_h_dim, activations=(None, None)),\n",
    "            LayerNorm(node_h_dim)\n",
    "        )\n",
    "        self.W_e = nn.Sequential(\n",
    "            GVP(edge_in_dim, edge_h_dim, activations=(None, None)),\n",
    "            LayerNorm(edge_h_dim)\n",
    "        )\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList(\n",
    "                GVPConvLayer(node_h_dim, edge_h_dim, drop_rate=drop_rate)\n",
    "            for _ in range(num_layers))\n",
    "\n",
    "\n",
    "        self.squeeze_layer = nn.Sequential(\n",
    "            nn.Linear(self.node_num*(node_h_dim[0]+node_h_dim[1]*3),1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=drop_rate),\n",
    "            nn.Linear(1024, 16)\n",
    "        )\n",
    "\n",
    "        self.unsqueeze_layer = nn.Sequential(\n",
    "            nn.Linear(16, 1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=drop_rate),\n",
    "            nn.Linear(1024, self.node_num*(node_h_dim[0]+node_h_dim[1]*3))\n",
    "        )\n",
    "\n",
    "\n",
    "        self.decoder_layers = nn.ModuleList(\n",
    "                GVPConvLayer(node_h_dim, edge_h_dim, drop_rate=drop_rate)\n",
    "            for _ in range(num_layers))\n",
    "\n",
    "        self.W_out = GVP(node_h_dim, (3, 0), activations=(None, None))\n",
    "\n",
    "\n",
    "    def forward(self, h_V, edge_index, h_E, output=None):\n",
    "        '''\n",
    "        Forward pass to be used at train-time or test-time.\n",
    "\n",
    "        :param h_V: tuple (s, V) of node embeddings\n",
    "        :param edge_index: `torch.Tensor` of shape [2, num_edges]\n",
    "        :param h_E: tuple (s, V) of edge embeddings\n",
    "        :param seq: int `torch.Tensor` of shape [num_nodes]\n",
    "        '''\n",
    "\n",
    "        h_V = (h_V[0].reshape(h_V[0].shape[0]*h_V[0].shape[1],h_V[0].shape[2]),\n",
    "               h_V[1].reshape(h_V[1].shape[0]*h_V[1].shape[1],h_V[1].shape[2],h_V[1].shape[3]))\n",
    "\n",
    "        h_E = (h_E[0].reshape(h_E[0].shape[0]*h_E[0].shape[1],h_E[0].shape[2]),\n",
    "               h_E[1].reshape(h_E[1].shape[0]*h_E[1].shape[1],h_E[1].shape[2],h_E[1].shape[3]))\n",
    "\n",
    "        h_V = self.W_v(h_V)\n",
    "        h_E = self.W_e(h_E)\n",
    "\n",
    "        for layer in self.encoder_layers:\n",
    "            h_V = layer(h_V, edge_index, h_E)\n",
    "\n",
    "        encoder_embeddings = h_V\n",
    "\n",
    "        flat_s = h_V[0].reshape(h_V[0].shape[0]//self.node_num, -1)\n",
    "        flat_V = h_V[1].reshape(h_V[1].shape[0]//self.node_num, -1)\n",
    "        h_V_stack = torch.cat((flat_s, flat_V),dim=1)\n",
    "        h_V_stack = self.squeeze_layer(h_V_stack)\n",
    "\n",
    "        h_V_small = torch.clone(h_V_stack)\n",
    "\n",
    "        if output is not None:\n",
    "          assert(h_V_stack.shape == output.shape)\n",
    "          h_V_stack = output.float()\n",
    "\n",
    "        h_V_stack = self.unsqueeze_layer(h_V_stack)\n",
    "\n",
    "        flat_s = h_V_stack[:,:self.node_num*encoder_embeddings[0].shape[1]]\n",
    "        flat_V = h_V_stack[:,self.node_num*encoder_embeddings[0].shape[1]:]\n",
    "        h_V = (flat_s.reshape(encoder_embeddings[0].shape),\n",
    "               flat_V.reshape(encoder_embeddings[1].shape))\n",
    "\n",
    "\n",
    "        for layer in self.decoder_layers:\n",
    "            h_V = layer(h_V, edge_index, h_E)\n",
    "        logits = self.W_out(h_V)\n",
    "\n",
    "        logits = logits.reshape(-1, self.node_num, 3)\n",
    "        return logits, h_V_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dI5tGZ43Td-O"
   },
   "outputs": [],
   "source": [
    "def train_gnn(model_dir, model, train_structures, n_epoch=20):\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    elif torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "\n",
    "    train_dataset = LigandDataset(train_structures)\n",
    "\n",
    "    train_dataloader = torch_geometric.loader.DenseDataLoader(train_dataset,\n",
    "                                                              batch_size=256,\n",
    "                                                              shuffle=True,\n",
    "                                                              num_workers=2)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    losses = torch.zeros(n_epoch,1)\n",
    "    #num_trained = len(glob.glob(os.path.join(model_dir,'epoch-*.pt')))\n",
    "    # if we haven't started training yet, n_epochs will go from 0 -> n_epoch\n",
    "    #n_epochs = list(range(num_trained, num_trained+n_epoch))\n",
    "    n_epochs = list(range(0,n_epoch))\n",
    "    for epoch in n_epochs:\n",
    "        batch_losses = []\n",
    "        start = time.time()\n",
    "        for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "            optimizer.zero_grad()\n",
    "            batch = batch.to(device)\n",
    "\n",
    "            nodes = (batch.node_s, batch.node_v)\n",
    "            edges = (batch.edge_s, batch.edge_v)\n",
    "            GT = batch.x\n",
    "\n",
    "            edge_index = batch.edge_index.permute([1,0,2])\n",
    "            edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "            pred,latent = model(nodes, edge_index, edges)\n",
    "\n",
    "            # make it so if close in latent space it is close in tica space\n",
    "            # so minimize norm of (pairwise dist in latent minus pairwise dist in tica)\n",
    "            loss = ((GT - pred) ** 2).mean()\n",
    "\n",
    "            #if i % 100 == 0:\n",
    "            #  print(\"batch\", i, \"loss\", loss.item())\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            #clear_output(wait=True)\n",
    "            #print(f'EPOCH {epoch} BATCH {i} TRAIN loss: {loss:.4f}')\n",
    "\n",
    "        path = os.path.join(model_dir, 'epoch-{}.pt'.format(epoch))\n",
    "        torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        # save avg loss value over batch for each epoch\n",
    "        losses[epoch] = np.mean(batch_losses)\n",
    "        torch.save(losses, os.path.join(model_dir, 'losses.pt'))\n",
    "\n",
    "        end = time.time()\n",
    "        t = round((end-start)/60,4)\n",
    "        print(f'----Epoch {epoch} | TRAIN loss: {losses[epoch, 0]} | Elapsed time: {t} minutes----')\n",
    "\n",
    "    view_output(model_dir, GT, pred, prefix='train_output_')\n",
    "    plot_loss(model_dir)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6z-aT08NTd7y"
   },
   "outputs": [],
   "source": [
    "def run_inference(model, model_dir, test_structures, batch_size=256):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    #test_structures = torch.load(os.path.join(model_dir,structures))\n",
    "    test_dataset = gvp.data.ProteinGraphDataset(test_structures)\n",
    "    test_dataloader = torch_geometric.loader.DenseDataLoader(test_dataset,\n",
    "                                                             batch_size=batch_size,\n",
    "                                                             shuffle=False,\n",
    "                                                             num_workers=2)\n",
    "\n",
    "    model.eval()\n",
    "    latents, preds, GTs = ([] for i in range(3))\n",
    "    losses=[]\n",
    "    for i, batch in enumerate(tqdm(test_dataloader)):\n",
    "        batch = batch.to(device)\n",
    "        nodes = (batch.node_s, batch.node_v)\n",
    "        edges = (batch.edge_s, batch.edge_v)\n",
    "        GT = batch.x\n",
    "        edge_index = batch.edge_index.permute([1,0,2])\n",
    "        edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "        pred, latent = model(nodes, edge_index, edges)\n",
    "\n",
    "        loss = ((GT - pred) ** 2).mean()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "          print(\"batch\", i, \"loss\", loss.item())\n",
    "        losses.append(loss.item())\n",
    "\n",
    "\n",
    "        GTs.extend(GT.cpu().detach().numpy())\n",
    "        latents.extend(latent.cpu().detach().numpy())\n",
    "        preds.extend(pred.cpu().detach().numpy())\n",
    "    print(\"TEST LOSS: \", np.mean(losses))\n",
    "    torch.save(GTs, os.path.join(model_dir, 'inference_GTs.pt'))\n",
    "    torch.save(latents, os.path.join(model_dir, 'inference_latents.pt'))\n",
    "    torch.save(preds, os.path.join(model_dir, 'inference_preds.pt'))\n",
    "    view_output(model_dir, GT, pred, prefix='test_output_')\n",
    "    return latents, preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ip2YxDcKTTrp"
   },
   "outputs": [],
   "source": [
    "def view_output(model_dir, GT, pred, prefix=''):\n",
    "    gt_coords = np.squeeze(GT.cpu().detach().numpy())\n",
    "    pred_coords = np.squeeze(pred.cpu().detach().numpy())\n",
    "    print(pred_coords.shape)\n",
    "    gt_coords = gt_coords.reshape(-1,3)\n",
    "    pred_coords = pred_coords.reshape(-1,3)\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(gt_coords[:,0], gt_coords[:,1], gt_coords[:,2])\n",
    "    ax.scatter(pred_coords[:,0], pred_coords[:,1], pred_coords[:,2])\n",
    "    fig.savefig(os.path.join(model_dir,prefix+\"gnn_pred_and_GT.png\"))\n",
    "\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(projection='3d')\n",
    "    ax.scatter(gt_coords[:,0]-pred_coords[:,0],\n",
    "            gt_coords[:,1]-pred_coords[:,1],\n",
    "            gt_coords[:,2]-pred_coords[:,2])\n",
    "    fig.savefig(os.path.join(model_dir,prefix+\"gnn_GT_-_pred.png\"))\n",
    "    return\n",
    "\n",
    "def plot_loss(model_dir, prefix=''):\n",
    "    losses = torch.load(os.path.join(model_dir, prefix+'losses.pt'))\n",
    "    fig, ax = plt.subplots()\n",
    "    loss = ax.plot(range(0,losses.shape[0]), losses,'-.')\n",
    "    fig.title('Loss')\n",
    "    #ax.legend(loss, (f'loss1 + {weight}*loss2', 'loss1', 'loss2'))\n",
    "    print(\"COMBINED LOSS: \", losses)\n",
    "    fig.savefig(os.path.join(model_dir,'loss.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "guAbvRA3TToa"
   },
   "outputs": [],
   "source": [
    "def random_seed(seed=42, rank=0):\n",
    "    torch.manual_seed(seed + rank)\n",
    "    np.random.seed(seed + rank)\n",
    "    random.seed(seed + rank)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jehocp9Q4vBl"
   },
   "source": [
    "# Get train/test structures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gbi32142H3ot"
   },
   "outputs": [],
   "source": [
    "seed = 7\n",
    "test_frac = 0.2\n",
    "train_drop = 0\n",
    "\n",
    "random_seed(seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XIRV1i1gH5rQ",
    "outputId": "3be87ab6-4268-4314-83e1-e69ae1ae6971"
   },
   "outputs": [],
   "source": [
    "pdb = 'data/fs-peptide.pdb'\n",
    "files = [f'data/trajectory-{i}.xtc' for i in range(1,29)]\n",
    "np.random.seed(seed)\n",
    "train_files = np.random.choice(files, size=int(len(files)* (1-test_frac)), replace=False)\n",
    "test_files = np.setdiff1d(files, train_files)\n",
    "train_files = np.random.choice(train_files, size=int(len(train_files)* (1 - train_drop)), replace=False)\n",
    "\n",
    "train_structures = create_structures(train_files, pdb)\n",
    "train_struct = list(train_structures.values())\n",
    "test_structures = create_structures(test_files, pdb)\n",
    "test_struct = list(test_structures.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4j6IMAYxWIdK",
    "outputId": "0dd1b05d-7b26-4e7c-8327-280bb52e67f1"
   },
   "outputs": [],
   "source": [
    "print(test_files)\n",
    "print(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AsYzYS0WH9p4"
   },
   "outputs": [],
   "source": [
    "model_dir = './gnn_model/'\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "\n",
    "node_h_dim = (100, 16)\n",
    "edge_h_dim = (32, 1)\n",
    "node_in_dim = (6, 3) #node dimensions in input graph, should be (6, 3) if using features from GVP-GNN\n",
    "edge_in_dim = (32, 1) #edge dimensions in input graph should be (32, 1) if using original features from GVP-GNN\n",
    "model = GCAE(node_in_dim, node_h_dim, edge_in_dim, edge_h_dim, node_num=21).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykcw_oU5IR2r"
   },
   "source": [
    "# TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kyb5L6bATTfS",
    "outputId": "76d4ede9-0fff-4828-c81c-aaef15a0e804"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model = train_gnn(model_dir, model, train_struct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MP7CtKOPLeew"
   },
   "source": [
    "# Train further\n",
    "\n",
    "load in a starting model and train more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OIvLbm1ZLdvJ"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir,'epoch-7.pt'), map_location=torch.device('cpu')))\n",
    "\n",
    "train_dataset = LigandDataset(train_struct)\n",
    "\n",
    "train_dataloader = torch_geometric.loader.DenseDataLoader(train_dataset,\n",
    "                                                          batch_size=256,\n",
    "                                                          shuffle=True,\n",
    "                                                          num_workers=4)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "n_epoch = 20\n",
    "\n",
    "losses = torch.zeros(n_epoch,1)\n",
    "#num_trained = len(glob.glob(os.path.join(model_dir,'epoch-*.pt')))\n",
    "# if we haven't started training yet, n_epochs will go from 0 -> n_epoch\n",
    "n_epochs = list(range(8, 8+n_epoch))\n",
    "#n_epochs = list(range(0,n_epoch))\n",
    "for epoch in n_epochs:\n",
    "    batch_losses = []\n",
    "    start = time.time()\n",
    "    for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "        optimizer.zero_grad()\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        nodes = (batch.node_s, batch.node_v)\n",
    "        edges = (batch.edge_s, batch.edge_v)\n",
    "        GT = batch.x\n",
    "\n",
    "        edge_index = batch.edge_index.permute([1,0,2])\n",
    "        edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "        pred,latent = model(nodes, edge_index, edges)\n",
    "\n",
    "        # make it so if close in latent space it is close in tica space\n",
    "        # so minimize norm of (pairwise dist in latent minus pairwise dist in tica)\n",
    "        loss = ((GT - pred) ** 2).mean()\n",
    "\n",
    "        if i % 100 == 0:\n",
    "          print(\"batch\", i, \"loss\", loss.item())\n",
    "\n",
    "        batch_losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #clear_output(wait=True)\n",
    "        #print(f'EPOCH {epoch} BATCH {i} TRAIN loss: {loss:.4f}')\n",
    "\n",
    "    path = os.path.join(model_dir, 'epoch-{}.pt'.format(epoch))\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # save avg loss value over batch for each epoch\n",
    "    losses[epoch] = np.mean(batch_losses)\n",
    "    torch.save(losses, os.path.join(model_dir, 'losses.pt'))\n",
    "\n",
    "    end = time.time()\n",
    "    t = round((end-start)/60,4)\n",
    "    print(f'----Epoch {epoch} | TRAIN loss: {losses[epoch, 0]} | Elapsed time: {t} minutes----')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nINfKAWGIVxP"
   },
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FhzhYORKLU-a",
    "outputId": "38efe01f-153d-43ef-eb06-45501f018027"
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(model_dir,'epoch-17.pt'))) #, map_location=torch.device('cpu')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X_BtT40NLaFg"
   },
   "source": [
    "# Get embeddings\n",
    "get train/test GTs, predictions, and latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vLkL8L6EPPas",
    "outputId": "0876260f-f7db-4e49-db5b-8361996a08a5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "train_dataset = LigandDataset(train_struct)\n",
    "\n",
    "train_dataloader = torch_geometric.loader.DenseDataLoader(train_dataset,\n",
    "                                                              batch_size=256,\n",
    "                                                              shuffle=False,\n",
    "                                                              num_workers=2)\n",
    "latents, preds, GTs = ([] for i in range(3))\n",
    "losses=[]\n",
    "for i, batch in enumerate(tqdm(train_dataloader)):\n",
    "      batch = batch.to(device)\n",
    "      nodes = (batch.node_s, batch.node_v)\n",
    "      edges = (batch.edge_s, batch.edge_v)\n",
    "      GT = batch.x\n",
    "      edge_index = batch.edge_index.permute([1,0,2])\n",
    "      edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "      pred, latent = model(nodes, edge_index, edges)\n",
    "\n",
    "      loss = ((GT - pred) ** 2).mean()\n",
    "\n",
    "      if i % 100 == 0:\n",
    "        print(\"batch\", i, \"loss\", loss.item())\n",
    "      losses.append(loss.item())\n",
    "\n",
    "\n",
    "      GTs.extend(GT.cpu().detach().numpy())\n",
    "      latents.extend(latent.cpu().detach().numpy())\n",
    "      preds.extend(pred.cpu().detach().numpy())\n",
    "print(\"TRAIN LOSS: \", np.mean(losses))\n",
    "torch.save(GTs, os.path.join(model_dir, 'train_GTs.pt'))\n",
    "torch.save(latents, os.path.join(model_dir, 'train_latents.pt'))\n",
    "torch.save(preds, os.path.join(model_dir, 'train_preds.pt'))\n",
    "#view_output(model_dir, GT, pred, prefix='test_output_')\n",
    "\n",
    "test_dataset = LigandDataset(test_struct)\n",
    "test_dataloader = torch_geometric.loader.DenseDataLoader(test_dataset,\n",
    "                                                             batch_size=256,\n",
    "                                                             shuffle=False,\n",
    "                                                             num_workers=2)\n",
    "\n",
    "model.eval()\n",
    "latents, preds, GTs = ([] for i in range(3))\n",
    "losses=[]\n",
    "for i, batch in enumerate(tqdm(test_dataloader)):\n",
    "  batch = batch.to(device)\n",
    "  nodes = (batch.node_s, batch.node_v)\n",
    "  edges = (batch.edge_s, batch.edge_v)\n",
    "  GT = batch.x\n",
    "  edge_index = batch.edge_index.permute([1,0,2])\n",
    "  edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "  pred, latent = model(nodes, edge_index, edges)\n",
    "\n",
    "  loss = ((GT - pred) ** 2).mean()\n",
    "\n",
    "  if i % 100 == 0:\n",
    "    print(\"batch\", i, \"loss\", loss.item())\n",
    "  losses.append(loss.item())\n",
    "\n",
    "\n",
    "  GTs.extend(GT.cpu().detach().numpy())\n",
    "  latents.extend(latent.cpu().detach().numpy())\n",
    "  preds.extend(pred.cpu().detach().numpy())\n",
    "print(\"TEST LOSS: \", np.mean(losses))\n",
    "torch.save(GTs, os.path.join(model_dir, 'test_GTs.pt'))\n",
    "torch.save(latents, os.path.join(model_dir, 'test_latents.pt'))\n",
    "torch.save(preds, os.path.join(model_dir, 'test_preds.pt'))\n",
    "view_output(model_dir, GT, pred, prefix='test_output_')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zpj4iYwnFzjH"
   },
   "source": [
    "# Decode output for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0d_KJ9wrGQuQ"
   },
   "outputs": [],
   "source": [
    "test_pred = torch.load('non_weightedtest_preds_199.pt')\n",
    "test_pred = test_pred.reshape(-1,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPRlIdweGrms",
    "outputId": "bb4453a6-d19f-4018-c5b4-2b03d00d31ba"
   },
   "outputs": [],
   "source": [
    "test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BE8VtRU7NA_h",
    "outputId": "a2befd3b-7864-4dce-e3aa-9517e2d00eaa"
   },
   "outputs": [],
   "source": [
    "test_GTs = np.array(torch.load('gnn_model/test_GTs.pt'))\n",
    "print(\"TEST GTs shape: \", test_GTs.shape)\n",
    "\n",
    "test_GTs_reshape = test_GTs.reshape(-1, 10000, 21, 3)\n",
    "print(\"thus GTs: \", test_GTs_reshape.shape)\n",
    "test_GTs_reshape = test_GTs.reshape(-1, 1000, 21,3)\n",
    "print(\"thus GTs: \", test_GTs_reshape.shape)\n",
    "\n",
    "\n",
    "X_gts = test_GTs_reshape[:,:-1,:,:]\n",
    "\n",
    "y_gts = test_GTs_reshape[:,1:,:,:]\n",
    "print(X_gts.shape)\n",
    "print(y_gts.shape)\n",
    "\n",
    "y_gts = y_gts.reshape(-1, 21,3)\n",
    "print(y_gts.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D-oSon8-NBBm"
   },
   "outputs": [],
   "source": [
    "new_test_struct = []\n",
    "for i in range(60*999):\n",
    "  coords = test_struct[i+1]['coords']\n",
    "  name = test_struct[i+1]['name']\n",
    "  seq = test_struct[i+1]['seq']\n",
    "  new_test_struct.append({'coords':coords,\n",
    "                          'name':name,\n",
    "                          'seq':seq})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CuCjcQIKlaf"
   },
   "outputs": [],
   "source": [
    "output=torch.tensor(test_pred).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4Eb0_brNA87",
    "outputId": "f48d6ab7-64ad-4249-cd36-0f1e2eec1ee5"
   },
   "outputs": [],
   "source": [
    "test_decode_dataset = LigandDataset(new_test_struct)\n",
    "test_decode_dataloader = torch_geometric.loader.DenseDataLoader(test_decode_dataset,\n",
    "                                                                batch_size=256,\n",
    "                                                                shuffle=False,\n",
    "                                                                num_workers=2)\n",
    "model = GCAE2(node_in_dim, node_h_dim, edge_in_dim, edge_h_dim, node_num=21).to(device)\n",
    "model.load_state_dict(torch.load('gnn_model/epoch-17.pt'))\n",
    "output_coords = []\n",
    "for i, batch in enumerate(tqdm(test_decode_dataloader)):\n",
    "    batch = batch.to(device)\n",
    "    if i != 234:\n",
    "      batch_output = output[i*256:i*256+256,:]\n",
    "    else:\n",
    "      batch_output = output[i*256:, :]\n",
    "    nodes = (batch.node_s, batch.node_v)\n",
    "    edges = (batch.edge_s, batch.edge_v)\n",
    "    GT = batch.x\n",
    "\n",
    "    edge_index = batch.edge_index.permute([1,0,2])\n",
    "    edge_index = edge_index.reshape(2, -1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        decoded,latent = model(nodes, edge_index, edges, batch_output)\n",
    "\n",
    "    output_coords.extend(decoded.cpu().detach().numpy())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JmYBBPUPNA6T",
    "outputId": "58edbb54-ce78-4cb5-f8a6-d55158e75b23"
   },
   "outputs": [],
   "source": [
    "output_coords = torch.tensor(output_coords)\n",
    "print(output_coords.shape)\n",
    "\n",
    "torch.save(output_coords, 'test_pred_decoded.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ctTLl-61NA3-"
   },
   "outputs": [],
   "source": [
    "test_preds_decoded = np.array(output_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pD4Dk2yEtOrm"
   },
   "source": [
    "# Calc loss on GNN encode -> transformer -> GNN decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8y0_1h0O6tjm"
   },
   "outputs": [],
   "source": [
    "test_preds_decoded = np.array(torch.load('gnn_model/test_pred_decoded.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zUAapQKNxgi3",
    "outputId": "7ef1ad26-2bc6-4d2d-8b84-46020b9f3a1c"
   },
   "outputs": [],
   "source": [
    "# this block is assuming that test_preds_decoded and\n",
    "#     y_gts are in memory and are shaped (60*999, 21, 3)\n",
    "assert(y_gts.shape == test_preds_decoded.shape)\n",
    "losses = []\n",
    "for i in range(60*999):\n",
    "  losses.append((((y_gts[i,:,:] - test_preds_decoded[i,:,:])**2).mean()).item())\n",
    "\n",
    "print(\"LOSSES: \", np.mean(losses), np.min(losses), np.max(losses))\n",
    "\n",
    "\n",
    "print(((y_gts - test_preds_decoded)**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_adkZna-y77v",
    "outputId": "fa05f5bb-4a92-41a1-e557-0b750ecc084b"
   },
   "outputs": [],
   "source": [
    "10*np.sqrt(np.mean(losses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "id": "DVJNSMCuy7xJ",
    "outputId": "656f56c2-9e74-4ff2-e368-91f29dff1335"
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 200#14319 #43328#, 35739, 14319 46004\n",
    "example = np.array(test_preds_decoded[i,:,:])\n",
    "test = y_gts[i,:,:]\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "test = y_gts[i,:,:]\n",
    "ax.plot(test[:,0],\n",
    "        test[:,1],\n",
    "        test[:,2],lw=2, label='Input')\n",
    "ax.plot(example[:,0],\n",
    "        example[:,1],\n",
    "        example[:,2], c='darkorange', lw=2, label='Predicted')\n",
    "\n",
    "\n",
    "plt.title(\"Coordinates - Avg loss 2.1$\\AA$\")\n",
    "plt.xlabel('nm')\n",
    "plt.ylabel('nm')\n",
    "\n",
    "ax.legend()\n",
    "fig.savefig('GNN_pred.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUAtvj3f8XBC"
   },
   "source": [
    "# Visualize output of GCAE itself\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "B9iLXOgn8pac",
    "outputId": "2faf2569-a596-4d26-ff08-5274785ea85b"
   },
   "outputs": [],
   "source": [
    "GTs = np.array(torch.load('gnn_model/epoch0test_GTs.pt'))\n",
    "preds = np.array(torch.load('gnn_model/epoch0test_preds.pt'))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "i = 210\n",
    "ax.plot(GTs[i,:,0],\n",
    "        GTs[i,:,1],\n",
    "        GTs[i,:,2], lw=2, label='Input')\n",
    "ax.plot(preds[i,:,0],\n",
    "        preds[i,:,1],\n",
    "        preds[i,:,2],lw=2, c='darkorange', label='Reconstructed output')\n",
    "plt.title(\"Model prediction after 1 epoch\")\n",
    "ax.legend()\n",
    "plt.xlabel('nm', fontsize=15)\n",
    "plt.ylabel('nm', fontsize=15)\n",
    "#plt.show()\n",
    "plt.savefig('gnn_model-1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 439
    },
    "id": "pRJmZKIVjP91",
    "outputId": "5921396e-5959-464a-819f-3136dd8d3510"
   },
   "outputs": [],
   "source": [
    "GTs = np.array(torch.load('gnn_model/epoch17test_GTs.pt'))\n",
    "preds = np.array(torch.load('gnn_model/epoch17test_preds.pt'))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(GTs[i,:,0],\n",
    "        GTs[i,:,1],\n",
    "        GTs[i,:,2], lw=2, label='Input')\n",
    "ax.plot(preds[i,:,0],\n",
    "        preds[i,:,1],\n",
    "        preds[i,:,2],lw=2, c='darkorange', label='Reconstructed output')\n",
    "plt.title(\"Model prediction after 18 epoch\")\n",
    "ax.legend()\n",
    "plt.xlabel('nm', fontsize=15)\n",
    "plt.ylabel('nm', fontsize=15)\n",
    "#plt.show()\n",
    "plt.savefig('gnn_model-17.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdHWWe-p8pP1",
    "outputId": "f3df9565-f4c3-4dca-a2f5-914427622dda"
   },
   "outputs": [],
   "source": [
    "((GTs - preds)**2).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VS4CGDaz8pM_",
    "outputId": "c958d333-ad4c-4bf3-8816-efa2f4802140"
   },
   "outputs": [],
   "source": [
    "np.sqrt(((GTs - preds)**2).mean())*10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LAkjEZseS7wT"
   },
   "source": [
    "# Visualize output of regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3DVKi6VwOcTR"
   },
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "font = {'family': 'sans-serif', 'weight':'normal', 'size'   : 15}\n",
    "\n",
    "matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 436
    },
    "id": "Q3hBRrDBS9kq",
    "outputId": "568c62cf-12b1-427e-e374-c5262e7bb993"
   },
   "outputs": [],
   "source": [
    "\n",
    "reg_autoreg_pred = np.array(torch.load('REGULARIZEDtest_autoregressive_preds_9.pt'))\n",
    "print(reg_autoreg_pred.shape)\n",
    "reg_autoreg_pred = reg_autoreg_pred.reshape(-1,88,3)\n",
    "\n",
    "print(reg_autoreg_pred.shape)\n",
    "reg_autoreg_pred = reg_autoreg_pred[:, 2:-2 ,:]\n",
    "print(reg_autoreg_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "tEGFS6RmT9LW",
    "outputId": "c7478b2c-645e-4d10-a248-8902530d5295"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "i_s = [4*i+1 for i in range(0,84//4)]\n",
    "j = 12345\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(reg_autoreg_pred[j,i_s,0],\n",
    "        reg_autoreg_pred[j,i_s,1],\n",
    "        reg_autoreg_pred[j,i_s,2])\n",
    "plt.title(\"Autoregressive prediction - regularized\")\n",
    "fig.savefig('reg_autoreg_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ztvk_yRX1QmP"
   },
   "outputs": [],
   "source": [
    "import mdtraj as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 534
    },
    "id": "elMCJ8Og1QSh",
    "outputId": "3c38541c-27d0-4572-8128-26bbecfd077d"
   },
   "outputs": [],
   "source": [
    "topology = md.load('data/fs-peptide.pdb').topology\n",
    "#topology = topology.atom_slice(topology.select(\"protein and backbone\"))\n",
    "traj = md.load('gnn_model/OUTPUT_BACKBONE_test_2.pdb')#, top='data/fs-peptide.pdb')\n",
    "print(traj)\n",
    "i_s = [4*i+3 for i in range(84//4)]\n",
    "print(i_s)\n",
    "CA_atoms = traj.atom_slice(i_s)\n",
    "CA_coords = CA_atoms.xyz\n",
    "\n",
    "traj2 = md.load('gnn_model/TEST_BACKBONE-1.pdb')\n",
    "print(traj2)\n",
    "CA_t_coords = traj2.xyz\n",
    "\n",
    "coords = test_struct[0]['coords']\n",
    "print(coords.shape)\n",
    "\n",
    "i = np.argmin(((CA_coords[0,:,:] - coords[:,1,:])**2).mean())\n",
    "\n",
    "#traj = traj[12345]\n",
    "#topology = md.load('data/fs-peptide.pdb').topology\n",
    "\n",
    "#CA_atoms = traj.atom_slice(topology.select(\"protein and name CA\"))\n",
    "#print(len(CA_atoms))\n",
    "#CA_coords = CA_atoms.xyz\n",
    "print(CA_coords.shape)\n",
    "j=0\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(coords[:,1,0],\n",
    "        coords[:,1,1],\n",
    "        coords[:,1,2], lw=2, label='Input')\n",
    "#ax.plot(CA_t_coords[j,i_s,0],\n",
    "#        CA_t_coords[j,i_s,1],\n",
    "#        CA_t_coords[j,i_s,2], lw=2,  label='Input')\n",
    "ax.plot(CA_coords[j,:,0],\n",
    "        CA_coords[j,:,1],\n",
    "        CA_coords[j,:,2], lw=2, c='darkorange', label='Prediction')\n",
    "plt.title(\"Test prediction - regularized\")\n",
    "\n",
    "plt.xlabel(\"nm\")\n",
    "plt.ylabel(\"nm\")\n",
    "ax.legend()\n",
    "fig.savefig('test_reg_plot.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JJOYhygh1QJt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VWqx5GrS_xi"
   },
   "source": [
    "# Visualize output of non-regularized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "id": "Pqnzibv7TCXS",
    "outputId": "067bb6dc-7a8f-468c-ba02-94771c27d7aa"
   },
   "outputs": [],
   "source": [
    "autoreg_pred = np.array(torch.load('gnn_model/test_preds_9_no_reg.pt'))\n",
    "print(autoreg_pred.shape)\n",
    "autoreg_pred = autoreg_pred.reshape(-1,88,3)\n",
    "\n",
    "print(autoreg_pred.shape)\n",
    "autoreg_pred = autoreg_pred[:, 2:-2 ,:]\n",
    "print(autoreg_pred.shape)\n",
    "\n",
    "coords = test_struct[0]['coords']\n",
    "print(coords.shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i_s = [4*i+1 for i in range(0,84//4)]\n",
    "j = 47000\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(projection='3d')\n",
    "ax.plot(coords[:,2,0],\n",
    "        coords[:,2,1],\n",
    "        coords[:,2,2], lw=2, label='Input')\n",
    "ax.plot(autoreg_pred[j,i_s,0],\n",
    "        autoreg_pred[j,i_s,1],\n",
    "        autoreg_pred[j,i_s,2], c='darkorange', lw=2, label='Prediction')\n",
    "plt.title(\"Autoregressive Prediction\")\n",
    "\n",
    "ax.legend()\n",
    "plt.xlabel('nm')\n",
    "plt.ylabel('nm')\n",
    "fig.savefig(\"noreg_test_plot.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "O4eY__GdogsY",
    "DtAkBktV41S6",
    "GDVme0yw4xuJ",
    "jehocp9Q4vBl",
    "Ykcw_oU5IR2r",
    "MP7CtKOPLeew",
    "nINfKAWGIVxP",
    "X_BtT40NLaFg",
    "zpj4iYwnFzjH",
    "pD4Dk2yEtOrm",
    "gUAtvj3f8XBC",
    "LAkjEZseS7wT",
    "_VWqx5GrS_xi"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
